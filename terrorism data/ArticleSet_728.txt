"The tech industry's long-running dispute with the government over encryption practices flared when Apple this week opposed a court order for the technology company to unlock an iPhone used by one of the San Bernardino, Calif., killers.
In a defiant 1,100-word letter to customers on Wednesday, the company's chief executive, Timothy D. Cook, called for a public discussion about privacy rights.
The topic ignited a heated debate on nytimes.com and on The Times's social media accounts. Nearly 5,000 comments had been submitted (as of 1 p.m. Eastern time on Thursday) on related articles and on The Times's Facebook page.
Readers were split over their answers to the question: Should the government be able to unlock your iPhone?
\"So let me get this straight: If Apple was the proprietor of a storage locker facility, and the government obtained a court-issued warrant to search the locker of a criminal suspect, Apple would not unlock the storage unit subject to the government's warrant?\" wrote Chad in Oregon.
Rich Comstock said on Facebook: \"Switch out iPhone and replace it with the word 'house.' If two suspected felons were wanted for murder and the F.B.I. or police felt there was compelling (and corroborating) evidence located at the house, they would place these facts before a judge to obtain a legal and appropriate search warrant -- all coming under the Fourth Amendment and Miranda rights.\"
Benjamin Casey replied, \"Actually the F.B.I. is asking for the keys to everyone's house and cameras inside to see what's going on all the time.\"
jonnyballgame in New York City wrote: \"Think of it this way: If a manufacturer of toy chests was ordered by the government to give it a master key so it could open the toy chest of a terrorist in order to conduct a validly issued search warrant, would we really think that company was standing up for liberty, or would we think they were exploiting the issue to be difficult and give the optics of being on the side of 'liberty' (and to help undermine Google's massive worldwide market share)?\"
Many readers agreed that the F.B.I.'s request to access the iPhone could set a dangerous precedent.
Fredd, in Denver, who said he had over 30 years experience working in the software and database industry, wrote: \"If you provide a back door, it's only a matter of time before nefarious people exploit it. ... All the government will end up doing is to weaken security for tens of millions to catch a few, and it won't be long before those few figure out how to write their own encryption to circumvent the back door problem.\"
Scipio, in Washington, agreed: \"This is indeed a testament to Apple's incredibly strong encryption.\"
Not everyone was so quick to simply side with Apple.
Matthew Schenker, who called himself a \"coder,\" suggested that there was a way to satisfy both the F.B.I. and the technology company. He wrote: \"I know there is always a way to code something with ethical limitations. For example, Apple could create a temporary, self-destructing device ID that must be issued from Apple and is only accessible within a certain time frame, and with a certain algorithm. Apple could hold that temporary ID and grant access on a case-by-case basis, rendering the 'back door' useless without it.\"
He added, \"This might sound complicated, but from a coding perspective it's not.\"
Diane Olberg, an Apple user in California who said she was a member of the Electronic Frontier Foundation, a digital rights group, said that the company should unlock the phone because these are extraordinary circumstances that override a right to privacy.
\"An even better path for Apple and E.F.F. might be to work with the government to set standards for special cases when phones will be unlocked, such as this one,\" she wrote. \"Yes this may be a slippery slope, but that's why we need standards for behavior and expectations for consumers.\"
The most popular reader comment on this issue, with over 1,200 recommendations, was from Randy Harris in Canada. He wrote: \"If unlocking this particular phone will assist authorities to investigate a terrorist attack that resulted with mass casualties then do it! Unlocking this particular phone doesn't threaten my privacy, but protecting the privacy of people like terrorists threatens all of our safety.\"
Henry Bechard agreed: \"Privacy has its limits, especially when all our lives are put at risk by those whose beliefs call for our destruction.\"
Some readers questioned what other options the F.B.I. might have.
J Lawrence in Houston wrote: \"The F.B.I. has the phone. Currently there exists no method for unlocking the phone. So the judge is mandating that Apple provide skilled labor to the F.B.I. to unlock the phone? Shouldn't it be the job of the F.B.I. to hire software engineers that figure out how to unlock the phone themselves?\"
Todd in the Bay Area wrote, \"I'm sympathetic to the government's case, but what do they expect to find that isn't pretty readily available elsewhere?\"
\"I guess I am just wondering why they didn't just cut the owner's thumb off and use it to access the phone?\" said John in Switzerland.
Many readers seemed to agree about one thing: The issue at stake appears bigger than one man's phone.
On Facebook, Jaimee Krupilis asked: \"Why doesn't the F.B.I. release the phone to Apple and allow them to access the device instead of needing a backdoor specially designed for them? I trust Tim Cook and the rest of the people at Apple with my nudes more than I trust the F.B.I.\"
Benjamin Casey replied: \"Apple says no, we will not create a thing so powerful it could destroy the very nature of digital privacy. This isn't just about the one phone.\"
Word count: 973
Copyright New York Times Company Feb 19, 2016"
