"At first glance, the question of unlocking the iPhone of one of the terrorists who slaughtered 14 people in California in December seems straightforward enough. Just break into the device and see whether it holds any information about members of a sleeper cell, other planned attacks or any morsel that law enforcement could use to save American lives.
As for privacy rights, well, the gunman forfeited those when he died in a shootout with police. Moreover, he didn't even own the phone. It belonged to his employer, the San Bernardino County Department of Health, which has agreed to the search.
But here's the rub: The FBI can't get into the iPhone without the gunman's passcode. Using \"brute force\" hacking to race through all the possible passcodes won't work unless Apple writes software to disable a security feature that erases the phone's data after 10 wrong tries.
On Tuesday, a federal court ordered Apple to do just that, either by giving the FBI the software to make it happen or by keeping the software at the company and letting the FBI use it remotely. But Apple CEO Tim Cook said no, arguing that once Apple complies, the software would become a \"master key\" that could unlock hundreds of millions of other iPhones. Not only could government agents and police get into phones, so might hackers and cyber thieves. Governments in authoritarian countries might demand the same key.
So the matter of Syed Farook's modern device raises difficult age-old issues about the tension between privacy and security, issues far more complex than the partisans on both sides of the debate like to admit.
Reflecting that complexity, the USA TODAY Editorial Board failed to reach consensus after lengthy debate about Apple's defiance. No one had any interest in guarding the privacy of a mass murderer or giving haven to future ones. The stumbling block was whether Apple's compliance could unleash a genie that might make smartphone users in the U.S. and around the world easy prey, for reasons good or bad.
The best outcome to this showdown might be a compromise that keeps a single-use-only key confined to Apple's headquarters, combined with legislation that limits government access to extraordinary scenarios in which lives are at stake. But whether such an outcome is possible depends on an array of technical and political questions:
Can you get at the data in the terrorist's iPhone without putting other iPhones at risk?
If Apple created a key and kept it (or destroyed it), would that prevent hackers from ever getting it? Or is it inevitable that software would escape?
Is this particular phone even worth the fight and the precedent? Farook and his wife destroyed their personal iPhones. It's possible the gunman forgot about this work phone, but it's also possible he didn't destroy it because it held no evidence.
If the court order is upheld, will Apple and other companies build phones that even they can't hack into? And will politicians try to make that illegal?
Some of the answers will emerge as the case makes its way through the courts. This is just the first round in a fight that could reshape the way surveillance and crime-solving are carried out in the information age.
Word count: 561
(Copyright (c) 2016 USA Today. All Rights Reserved.)"
